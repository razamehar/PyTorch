{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "qRlb2Lnhdzf4",
        "SgJs_-pPeAHT",
        "LZVVwkpVeM8M"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Generator**"
      ],
      "metadata": {
        "id": "g-QLaLLJswgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility"
      ],
      "metadata": {
        "id": "qRlb2Lnhdzf4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NfcpnluzLzo",
        "outputId": "2ef24242-c05b-4d9a-f120-de3f5c4beecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "ae7dunqczT8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMU_RwfbzXt4",
        "outputId": "7ca637f6-f33e-4c84-ebf9-8981bf149790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence\n"
      ],
      "metadata": {
        "id": "x52A3E1K1zjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "\n",
        "def prediction(model, vocab, text):\n",
        "\n",
        "  # tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  # text -> numerical indices\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(padded_text)\n",
        "\n",
        "  # predicted index\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  # merge with text\n",
        "  return text + \" \" + list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "9KYpjm4HfKOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "SgJs_-pPeAHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"What is your full name?\n",
        "My name is Raza Mehar.\n",
        "\n",
        "What is your current location?\n",
        "I am currently based in Naples, Italy.\n",
        "\n",
        "What are your key professional roles?\n",
        "I work as a Data Scientist with expertise in Machine Learning and Deep Learning. I am also an advocate for AI for Good, leveraging artificial intelligence for meaningful and impactful applications.\n",
        "\n",
        "What is your highest educational qualification?\n",
        "I am pursuing an MS in Data Science at the University of Naples Federico II in Italy.\n",
        "\n",
        "Have you received any special academic distinctions?\n",
        "Yes, I was awarded Cum Laude in several courses, including Data Mining & Machine Learning, Statistical Learning & Data Analysis, AI System Engineering, Hardware & Software for Big Data, and Theory & Ethics of Big Data.\n",
        "\n",
        "Do you have any other degrees apart from your MS?\n",
        "Yes, I also hold an MBA from the Institute of Business Management, Pakistan, and a BS in Computer Engineering from Sir Syed University of Engineering & Technology, Pakistan.\n",
        "\n",
        "Have you obtained any certifications?\n",
        "Yes, I have certifications in Applied Machine Learning from the University of Michigan and Data Analytics from Google.\n",
        "\n",
        "What are your programming skills?\n",
        "I am proficient in Python, R, and SQL.\n",
        "\n",
        "What frameworks and libraries do you commonly use?\n",
        "I work extensively with TensorFlow, PyTorch, Scikit-Learn, Pandas, NumPy, Hugging Face, and LangChain.\n",
        "\n",
        "What tools and technologies are you familiar with?\n",
        "I have hands-on experience with Git, Docker, MLFlow, FastAPI, Postgres, and OpenAI.\n",
        "\n",
        "What are your key areas of expertise?\n",
        "My expertise includes Predictive Modeling, Natural Language Processing (NLP), and Large Language Models (LLMs).\n",
        "\n",
        "Do you have experience with data visualization?\n",
        "Yes, I use Matplotlib and Seaborn for data visualization.\n",
        "\n",
        "What are your core skills in AI and Data Science?\n",
        "My core skills include Machine Learning, Deep Learning, Generative AI, Data Analysis, and Data Mining.\n",
        "\n",
        "What is your English language proficiency?\n",
        "My English proficiency is at the C1 level.\n",
        "\n",
        "Have you worked as a Data Science intern?\n",
        "Yes, I worked as a Data Science Intern at Change2 s.r.l., where I researched emission factors, implemented web scraping and PDF parsing techniques, and conducted an in-depth analysis of sustainability in Italy’s food sector.\n",
        "\n",
        "Have you done any freelance work?\n",
        "Yes, I worked as a Machine Learning Engineer at Omdena Inc., where I developed an AI solution to predict indoor classroom temperatures in Tanzanian public schools using LSTM and ensemble methods.\n",
        "\n",
        "What was your previous work experience before data science?\n",
        "I worked as an HR Business Partner at Engro Polymer & Chemicals Limited in Pakistan, where I applied data analytics and predictive modeling, particularly Survival Analysis, to enhance HR strategies and reduce employee turnover.\n",
        "\n",
        "What are some of the projects you have worked on?\n",
        "I have worked on several projects, including a RAG-based chatbot that allows users to interact with their data, a political leaning detection model for news articles using BERT and LoRA, a plant disease detection system utilizing deep learning and clustering techniques, and a geo-analytics project for estimating market potential for Fater, a P&G subsidiary.\n",
        "\n",
        "Can you explain your chatbot project?\n",
        "Yes, I developed a conversational AI chatbot capable of reading and interacting with documents. It utilizes a Retrieval-Augmented Generation (RAG) model and incorporates few-shot learning and chain-of-thought reasoning techniques to provide accurate responses based on document contents.\n",
        "\n",
        "What was your political leaning detection project about?\n",
        "This project involved fine-tuning BERT using Low-Rank Adaptation (LoRA) to classify news articles as right-leaning, centrist, or left-leaning. I also optimized the model using post-training quantization (PTQ) to enhance its efficiency and performance.\n",
        "\n",
        "What was the focus of your plant disease detection project?\n",
        "I developed a robust system that combined non-negative matrix factorization, fuzzy clustering, and YOLO-based deep learning techniques for accurate plant disease identification.\n",
        "\n",
        "Can you describe your market potential estimation project?\n",
        "This project was aimed at assessing the diaper market potential for Fater by analyzing socio-demographic data, geographic information, and points of interest to refine revenue forecasts for Naples stores.\n",
        "\n",
        "How did you contribute to employee turnover reduction in your HR role?\n",
        "I used predictive analytics and Survival Analysis to identify at-risk employees and implemented targeted interventions, which led to a 5% reduction in turnover.\n",
        "\n",
        "Have you worked on AI solutions for social good?\n",
        "Yes, I contributed to an AI project for Open Development & Education that predicted indoor classroom temperatures in Tanzanian public schools, improving learning conditions for students.\n",
        "\n",
        "Are you actively involved in AI for Good initiatives?\n",
        "Yes, I advocate for AI for Good and have worked on various projects that leverage AI to create meaningful social impact.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "fLwm0Y_MzVuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing and Building Vocabulary"
      ],
      "metadata": {
        "id": "LZVVwkpVeM8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "t28bgAcszaHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "vocab = {'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30GxEjgzcfY",
        "outputId": "66429994-5817-4ec8-abee-1ac84c2739de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'your': 3,\n",
              " 'full': 4,\n",
              " 'name': 5,\n",
              " '?': 6,\n",
              " 'my': 7,\n",
              " 'raza': 8,\n",
              " 'mehar': 9,\n",
              " '.': 10,\n",
              " 'current': 11,\n",
              " 'location': 12,\n",
              " 'i': 13,\n",
              " 'am': 14,\n",
              " 'currently': 15,\n",
              " 'based': 16,\n",
              " 'in': 17,\n",
              " 'naples': 18,\n",
              " ',': 19,\n",
              " 'italy': 20,\n",
              " 'are': 21,\n",
              " 'key': 22,\n",
              " 'professional': 23,\n",
              " 'roles': 24,\n",
              " 'work': 25,\n",
              " 'as': 26,\n",
              " 'a': 27,\n",
              " 'data': 28,\n",
              " 'scientist': 29,\n",
              " 'with': 30,\n",
              " 'expertise': 31,\n",
              " 'machine': 32,\n",
              " 'learning': 33,\n",
              " 'and': 34,\n",
              " 'deep': 35,\n",
              " 'also': 36,\n",
              " 'an': 37,\n",
              " 'advocate': 38,\n",
              " 'for': 39,\n",
              " 'ai': 40,\n",
              " 'good': 41,\n",
              " 'leveraging': 42,\n",
              " 'artificial': 43,\n",
              " 'intelligence': 44,\n",
              " 'meaningful': 45,\n",
              " 'impactful': 46,\n",
              " 'applications': 47,\n",
              " 'highest': 48,\n",
              " 'educational': 49,\n",
              " 'qualification': 50,\n",
              " 'pursuing': 51,\n",
              " 'ms': 52,\n",
              " 'science': 53,\n",
              " 'at': 54,\n",
              " 'the': 55,\n",
              " 'university': 56,\n",
              " 'of': 57,\n",
              " 'federico': 58,\n",
              " 'ii': 59,\n",
              " 'have': 60,\n",
              " 'you': 61,\n",
              " 'received': 62,\n",
              " 'any': 63,\n",
              " 'special': 64,\n",
              " 'academic': 65,\n",
              " 'distinctions': 66,\n",
              " 'yes': 67,\n",
              " 'was': 68,\n",
              " 'awarded': 69,\n",
              " 'cum': 70,\n",
              " 'laude': 71,\n",
              " 'several': 72,\n",
              " 'courses': 73,\n",
              " 'including': 74,\n",
              " 'mining': 75,\n",
              " '&': 76,\n",
              " 'statistical': 77,\n",
              " 'analysis': 78,\n",
              " 'system': 79,\n",
              " 'engineering': 80,\n",
              " 'hardware': 81,\n",
              " 'software': 82,\n",
              " 'big': 83,\n",
              " 'theory': 84,\n",
              " 'ethics': 85,\n",
              " 'do': 86,\n",
              " 'other': 87,\n",
              " 'degrees': 88,\n",
              " 'apart': 89,\n",
              " 'from': 90,\n",
              " 'hold': 91,\n",
              " 'mba': 92,\n",
              " 'institute': 93,\n",
              " 'business': 94,\n",
              " 'management': 95,\n",
              " 'pakistan': 96,\n",
              " 'bs': 97,\n",
              " 'computer': 98,\n",
              " 'sir': 99,\n",
              " 'syed': 100,\n",
              " 'technology': 101,\n",
              " 'obtained': 102,\n",
              " 'certifications': 103,\n",
              " 'applied': 104,\n",
              " 'michigan': 105,\n",
              " 'analytics': 106,\n",
              " 'google': 107,\n",
              " 'programming': 108,\n",
              " 'skills': 109,\n",
              " 'proficient': 110,\n",
              " 'python': 111,\n",
              " 'r': 112,\n",
              " 'sql': 113,\n",
              " 'frameworks': 114,\n",
              " 'libraries': 115,\n",
              " 'commonly': 116,\n",
              " 'use': 117,\n",
              " 'extensively': 118,\n",
              " 'tensorflow': 119,\n",
              " 'pytorch': 120,\n",
              " 'scikit-learn': 121,\n",
              " 'pandas': 122,\n",
              " 'numpy': 123,\n",
              " 'hugging': 124,\n",
              " 'face': 125,\n",
              " 'langchain': 126,\n",
              " 'tools': 127,\n",
              " 'technologies': 128,\n",
              " 'familiar': 129,\n",
              " 'hands-on': 130,\n",
              " 'experience': 131,\n",
              " 'git': 132,\n",
              " 'docker': 133,\n",
              " 'mlflow': 134,\n",
              " 'fastapi': 135,\n",
              " 'postgres': 136,\n",
              " 'openai': 137,\n",
              " 'areas': 138,\n",
              " 'includes': 139,\n",
              " 'predictive': 140,\n",
              " 'modeling': 141,\n",
              " 'natural': 142,\n",
              " 'language': 143,\n",
              " 'processing': 144,\n",
              " '(': 145,\n",
              " 'nlp': 146,\n",
              " ')': 147,\n",
              " 'large': 148,\n",
              " 'models': 149,\n",
              " 'llms': 150,\n",
              " 'visualization': 151,\n",
              " 'matplotlib': 152,\n",
              " 'seaborn': 153,\n",
              " 'core': 154,\n",
              " 'include': 155,\n",
              " 'generative': 156,\n",
              " 'english': 157,\n",
              " 'proficiency': 158,\n",
              " 'c1': 159,\n",
              " 'level': 160,\n",
              " 'worked': 161,\n",
              " 'intern': 162,\n",
              " 'change2': 163,\n",
              " 's.r.l.': 164,\n",
              " 'where': 165,\n",
              " 'researched': 166,\n",
              " 'emission': 167,\n",
              " 'factors': 168,\n",
              " 'implemented': 169,\n",
              " 'web': 170,\n",
              " 'scraping': 171,\n",
              " 'pdf': 172,\n",
              " 'parsing': 173,\n",
              " 'techniques': 174,\n",
              " 'conducted': 175,\n",
              " 'in-depth': 176,\n",
              " 'sustainability': 177,\n",
              " '’': 178,\n",
              " 's': 179,\n",
              " 'food': 180,\n",
              " 'sector': 181,\n",
              " 'done': 182,\n",
              " 'freelance': 183,\n",
              " 'engineer': 184,\n",
              " 'omdena': 185,\n",
              " 'inc.': 186,\n",
              " 'developed': 187,\n",
              " 'solution': 188,\n",
              " 'to': 189,\n",
              " 'predict': 190,\n",
              " 'indoor': 191,\n",
              " 'classroom': 192,\n",
              " 'temperatures': 193,\n",
              " 'tanzanian': 194,\n",
              " 'public': 195,\n",
              " 'schools': 196,\n",
              " 'using': 197,\n",
              " 'lstm': 198,\n",
              " 'ensemble': 199,\n",
              " 'methods': 200,\n",
              " 'previous': 201,\n",
              " 'before': 202,\n",
              " 'hr': 203,\n",
              " 'partner': 204,\n",
              " 'engro': 205,\n",
              " 'polymer': 206,\n",
              " 'chemicals': 207,\n",
              " 'limited': 208,\n",
              " 'particularly': 209,\n",
              " 'survival': 210,\n",
              " 'enhance': 211,\n",
              " 'strategies': 212,\n",
              " 'reduce': 213,\n",
              " 'employee': 214,\n",
              " 'turnover': 215,\n",
              " 'some': 216,\n",
              " 'projects': 217,\n",
              " 'on': 218,\n",
              " 'rag-based': 219,\n",
              " 'chatbot': 220,\n",
              " 'that': 221,\n",
              " 'allows': 222,\n",
              " 'users': 223,\n",
              " 'interact': 224,\n",
              " 'their': 225,\n",
              " 'political': 226,\n",
              " 'leaning': 227,\n",
              " 'detection': 228,\n",
              " 'model': 229,\n",
              " 'news': 230,\n",
              " 'articles': 231,\n",
              " 'bert': 232,\n",
              " 'lora': 233,\n",
              " 'plant': 234,\n",
              " 'disease': 235,\n",
              " 'utilizing': 236,\n",
              " 'clustering': 237,\n",
              " 'geo-analytics': 238,\n",
              " 'project': 239,\n",
              " 'estimating': 240,\n",
              " 'market': 241,\n",
              " 'potential': 242,\n",
              " 'fater': 243,\n",
              " 'p': 244,\n",
              " 'g': 245,\n",
              " 'subsidiary': 246,\n",
              " 'can': 247,\n",
              " 'explain': 248,\n",
              " 'conversational': 249,\n",
              " 'capable': 250,\n",
              " 'reading': 251,\n",
              " 'interacting': 252,\n",
              " 'documents': 253,\n",
              " 'it': 254,\n",
              " 'utilizes': 255,\n",
              " 'retrieval-augmented': 256,\n",
              " 'generation': 257,\n",
              " 'rag': 258,\n",
              " 'incorporates': 259,\n",
              " 'few-shot': 260,\n",
              " 'chain-of-thought': 261,\n",
              " 'reasoning': 262,\n",
              " 'provide': 263,\n",
              " 'accurate': 264,\n",
              " 'responses': 265,\n",
              " 'document': 266,\n",
              " 'contents': 267,\n",
              " 'about': 268,\n",
              " 'this': 269,\n",
              " 'involved': 270,\n",
              " 'fine-tuning': 271,\n",
              " 'low-rank': 272,\n",
              " 'adaptation': 273,\n",
              " 'classify': 274,\n",
              " 'right-leaning': 275,\n",
              " 'centrist': 276,\n",
              " 'or': 277,\n",
              " 'left-leaning': 278,\n",
              " 'optimized': 279,\n",
              " 'post-training': 280,\n",
              " 'quantization': 281,\n",
              " 'ptq': 282,\n",
              " 'its': 283,\n",
              " 'efficiency': 284,\n",
              " 'performance': 285,\n",
              " 'focus': 286,\n",
              " 'robust': 287,\n",
              " 'combined': 288,\n",
              " 'non-negative': 289,\n",
              " 'matrix': 290,\n",
              " 'factorization': 291,\n",
              " 'fuzzy': 292,\n",
              " 'yolo-based': 293,\n",
              " 'identification': 294,\n",
              " 'describe': 295,\n",
              " 'estimation': 296,\n",
              " 'aimed': 297,\n",
              " 'assessing': 298,\n",
              " 'diaper': 299,\n",
              " 'by': 300,\n",
              " 'analyzing': 301,\n",
              " 'socio-demographic': 302,\n",
              " 'geographic': 303,\n",
              " 'information': 304,\n",
              " 'points': 305,\n",
              " 'interest': 306,\n",
              " 'refine': 307,\n",
              " 'revenue': 308,\n",
              " 'forecasts': 309,\n",
              " 'stores': 310,\n",
              " 'how': 311,\n",
              " 'did': 312,\n",
              " 'contribute': 313,\n",
              " 'reduction': 314,\n",
              " 'role': 315,\n",
              " 'used': 316,\n",
              " 'identify': 317,\n",
              " 'at-risk': 318,\n",
              " 'employees': 319,\n",
              " 'targeted': 320,\n",
              " 'interventions': 321,\n",
              " 'which': 322,\n",
              " 'led': 323,\n",
              " '5': 324,\n",
              " '%': 325,\n",
              " 'solutions': 326,\n",
              " 'social': 327,\n",
              " 'contributed': 328,\n",
              " 'open': 329,\n",
              " 'development': 330,\n",
              " 'education': 331,\n",
              " 'predicted': 332,\n",
              " 'improving': 333,\n",
              " 'conditions': 334,\n",
              " 'students': 335,\n",
              " 'actively': 336,\n",
              " 'initiatives': 337,\n",
              " 'various': 338,\n",
              " 'leverage': 339,\n",
              " 'create': 340,\n",
              " 'impact': 341}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOOEZ94P0dQ1",
        "outputId": "2133c1ba-f551-48aa-f858-2622cb63e009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "342"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "RefNavJe1Cva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))\n"
      ],
      "metadata": {
        "id": "eu66Zo3e1Wh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxJesAQC1et3",
        "outputId": "9ff11358-c76c-4061-a10e-118dafb0d01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genrating Training Sequence"
      ],
      "metadata": {
        "id": "UN5oUSPMey4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "80rIx4aq6ele"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aGJ0fy7swk",
        "outputId": "0f52b235-aa6d-47a5-b9c7-6aa2e3c9f9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "831"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrFzZ4DD8Anu",
        "outputId": "1b4e5721-f444-4ff6-de53-dcacbc9a9929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z_fiVZ8GRo",
        "outputId": "6c1f73e8-b39a-491d-ee8b-8831b1c9b2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bIcIRd088EN",
        "outputId": "c7d8d464-ca20-4a11-c12c-2b3239b2de77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "\n",
        "  padded_training_sequence.append([0]*(max(len_list) - len(sequence)) + sequence)"
      ],
      "metadata": {
        "id": "dtPg5uRN9Cc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqZssF989X-4",
        "outputId": "63e9d5d0-975a-4f1a-a00b-3ac6c94a3b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "Tz8fwCok90m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Dataset Class and Customer Data Loader"
      ],
      "metadata": {
        "id": "6XgBEqcLe5L2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHaeSuI_nJX",
        "outputId": "84b578e7-58e6-4970-90a4-2a7063ddd342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "831"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "7ZUeD3l6_oZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Model"
      ],
      "metadata": {
        "id": "VJK1PsyNfASd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Lvm7W6L1X6P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwq43NRYD3q",
        "outputId": "5f095ae6-a84a-4e1f-db18-aaa67ec5498d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(342, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=342, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1faORN1VYFdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch_x, batch_y in dataloader:\n",
        "\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "c00a77fc-96eb-473d-d580-81293360b574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 149.7055\n",
            "Epoch: 2, Loss: 135.2952\n",
            "Epoch: 3, Loss: 123.1533\n",
            "Epoch: 4, Loss: 112.9856\n",
            "Epoch: 5, Loss: 102.4809\n",
            "Epoch: 6, Loss: 92.8189\n",
            "Epoch: 7, Loss: 83.2178\n",
            "Epoch: 8, Loss: 74.1576\n",
            "Epoch: 9, Loss: 65.8017\n",
            "Epoch: 10, Loss: 58.1626\n",
            "Epoch: 11, Loss: 51.2166\n",
            "Epoch: 12, Loss: 44.9341\n",
            "Epoch: 13, Loss: 39.1595\n",
            "Epoch: 14, Loss: 34.2790\n",
            "Epoch: 15, Loss: 29.9575\n",
            "Epoch: 16, Loss: 26.3406\n",
            "Epoch: 17, Loss: 23.1417\n",
            "Epoch: 18, Loss: 20.5047\n",
            "Epoch: 19, Loss: 18.1699\n",
            "Epoch: 20, Loss: 16.3107\n",
            "Epoch: 21, Loss: 14.7385\n",
            "Epoch: 22, Loss: 13.3382\n",
            "Epoch: 23, Loss: 12.2564\n",
            "Epoch: 24, Loss: 11.2000\n",
            "Epoch: 25, Loss: 10.4396\n",
            "Epoch: 26, Loss: 9.7908\n",
            "Epoch: 27, Loss: 9.1701\n",
            "Epoch: 28, Loss: 8.6964\n",
            "Epoch: 29, Loss: 8.2401\n",
            "Epoch: 30, Loss: 7.8035\n",
            "Epoch: 31, Loss: 7.4427\n",
            "Epoch: 32, Loss: 7.1586\n",
            "Epoch: 33, Loss: 6.8659\n",
            "Epoch: 34, Loss: 6.6587\n",
            "Epoch: 35, Loss: 6.3499\n",
            "Epoch: 36, Loss: 6.2064\n",
            "Epoch: 37, Loss: 6.0505\n",
            "Epoch: 38, Loss: 5.8441\n",
            "Epoch: 39, Loss: 5.7522\n",
            "Epoch: 40, Loss: 5.6080\n",
            "Epoch: 41, Loss: 5.4994\n",
            "Epoch: 42, Loss: 5.3189\n",
            "Epoch: 43, Loss: 5.2585\n",
            "Epoch: 44, Loss: 5.1697\n",
            "Epoch: 45, Loss: 5.0649\n",
            "Epoch: 46, Loss: 4.9799\n",
            "Epoch: 47, Loss: 4.8938\n",
            "Epoch: 48, Loss: 4.8107\n",
            "Epoch: 49, Loss: 4.7314\n",
            "Epoch: 50, Loss: 4.7030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting"
      ],
      "metadata": {
        "id": "xdet_30EfP7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"My first name is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VsRgcJysbGCg",
        "outputId": "a0b805d0-a71c-456a-e743-839287c1ed97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My first name is raza'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"Yes, I also hold\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text = prediction(model, vocab, input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "ae8a7427-a1f4-4316-8c81-da17bab0c009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, I also hold an\n",
            "Yes, I also hold an mba\n",
            "Yes, I also hold an mba from\n",
            "Yes, I also hold an mba from the\n",
            "Yes, I also hold an mba from the institute\n",
            "Yes, I also hold an mba from the institute of\n",
            "Yes, I also hold an mba from the institute of business\n",
            "Yes, I also hold an mba from the institute of business management\n",
            "Yes, I also hold an mba from the institute of business management ,\n",
            "Yes, I also hold an mba from the institute of business management , pakistan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "JXsV4AnNXNnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "-Bpwp1uqfVjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # Get the predicted word indices\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Compare with actual labels\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Py7o0rJJc5pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25933f1a-93d0-4c60-edd8-7b0bb83a0bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 94.22%\n"
          ]
        }
      ]
    }
  ]
}